---
layout: post
title: Kaggle 입문
author: An Hyungjun
categories: [AI]
tags: [ai, summary, kaggle]
---

Kaggle 입문 지식을 정리한다.

참고 URL: https://github.com/baidoosik/kaggle-solving

# 기초 용어
- Kaggle: 예측모델 및 분석 대회 플랫폼
- Cross Validation: 데이터 셋을 테스트, 학습용으로 나눠서 모델의 정확도를 검증하는 기법

## 데이터 분석 흐름
- 문제 정의
- 데이터 수집
- 데이터 분석(Kaggle은 여기부터)
- Feature Engineering: 데이터를 컴퓨터가 학습할 수 있는 형태로 가공
	- Data Cleaning
	- Data Transformation
	- Feature Selection
	- PCA
- Modeling: 알고리즘 선정
- Validation: 선정된 알고리즘의 신뢰도 분석
- Testing: 실제 적용(Kaggle의 경우 제출)

## 데이터 시각화용 라이브러리들
- discrete: matplot, seaborn(countplot)
- continuous: seaborn(FacetGrid)

# Kaggle 평가 방식
- 데이터와 명세가 제공됨
- 문제마다 평가 방식(손실 함수)이 다름
- Late Submission을 통해 예측 결과 파일을 제출

# Feature Engineering
- 데이터를 Feature vector(숫자)로 변환하는 작업
- 데이터 분석 및 도메인 지식에 기반함

## null data 처리 필요
- null data: 수집되지 않은 데이터
- 시각화를 위해 "missingno"라이브러리를 쓸 수 있음

## 시각화, 조합, 통계(수치)로 보기
- insight를 얻기위해 사용됨

## 범위가 넓은 데이터의 경우 구간별로 맵핑
```python
[1  ~ 10) : 0
[10 ~ 20) : 1
[20 ~ 30) : 2
```

## Feature Selection
- 유효한 데이터만 학습에 사용하도록 선정하는 작업

### 분산이 낮은 feature 제거
### Random Forest Classifier
### PCA

# Ensemble(앙상블) 모델
- 다양한 모델의 예측 결과를 조합해서 사용하는 예측 모델
- 각 알고리즘은 독립이어야 함
- 오류 분류율이 적어도 50% 이상일 때 권장

## Bagging(Bootstrap Aggregation)
- 앙상블 학습법의 한 종류
- 분산을 줄이고 overfitting을 피할 수 있음
- 보통 Decision Tree, Random Forest에 적용됨

## Voting(다수결)
- 여러 모형에 soft 옵션을 통해 가중치를 둬서 결과를 예측


# Kaggle 점수를 높이는 몇 가지 아이디어
- 유의미한 Feature만 사용
- Feature를 domain 정보를 이용해서 가공
- 알고리즘 설정 값 변경

TODO: titanic 내용 추가해야함

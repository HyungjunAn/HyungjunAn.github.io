---
layout: post
title: 머신러닝 기초
author: An Hyungjun
categories: [AI]
tags: [ai, summary]
---

머신러닝 기초를 정리한다.

# 기초 용어

## 머신러닝과 데이터 사이언스
- 머신러닝: 데이터의 패턴을 찾아내는 과정
- 데이터 사이언스: 찾아낸 패턴에 의미를 부여하는 것

## 기계학습의 종류
- 지도학습: 정답 데이터가 있음
	- 회귀분석: 결과값을 예측하는 선을 찾는 것
	- 분류: 어떤 클래스에 속할 것인지를 판단하는 것
- 비지도학습: 정답 데이터가 없음
	- 클러스터링
- 강화학습: 에이전트가 보상을 최대화하는 (연속된)선택을 하도록 하는 방법

# 기초 선형 대수

## Scalar vs. Vector
- Scalar: 크기만 존재하는 양
- Vector: 크기와 방향이 함께 존재하는 양

## 벡터 공간 / 내적
- 놈(Norm): 벡터의 길이(원점으로부터의 거리), 제곱 합의 루트
- 내적(Euclidean inner product / Dot product): 각 원소 곱의 합

## 행렬
- 전치행렬: 행과 열을 뒤집음

# numpy
Python의 과학 컴퓨팅용 라이브러리

```python
import numpy an np

A = np.array([[11, 12],
			  [13, 14]])

B = np.array([[21, 22],
			  [23, 24]])

print(A)
```

## 원소 단위 계산
```python 
print(A * 2)
print(A ** 2)
print(2 ** A)
print(A * A)

print(A == B)
print(A > B)

np.logical_or(A1, A2)
np.logical_and(A1, A2)
```

## 행렬 단위 계산
```python
np.dot(A, B)

np.transpose(A)

np.linalg.inv(A)
```

## 스칼라화
```
np.sum(A)
A.sum(A)

A.min(A)
A.max(A)

A.argmin(A)
A.argmax(A)

np.all(A)
np.any(A)

np.linalg.norm(A)

np.mean(A)
np.median(A)
np.var(A)
np.std(A)
```

# 회귀분석
## 선형 회귀분석
- 데이터를 잘 설명하는 1차식 찾기
- 차이(Loss function)가 최소가 되게하는 계수 찾기
- Loss funtion의 최소점 찾기

## Loss function의 종류
- MSE(Mean Squared Error): 평균 제곱 오차, 차의 제곱의 합

## 다중선형 회귀분석
- 데이터가 2차원 이상

## 다항 회귀분석
- 데이터가 2차식 이상

# 분류(베이지안)

## 빈도주의 vs. 베이지안
- 빈도주의: 결과를 예측
- 베이지안: 확신 또는 믿음으로 해석

## 베이즈 법칙
- 잘 모르는 확률을 잘 아는 확률들로 구하기
```
P(A|X) = (P(X|A)P(A)) / P(X)
```

## Naive Bayes
- 어느 집단에 있을 확률이 더 높은가?
```
P(A|X), P(B|X)

P(X|A)P(A), P(X|B)P(B)

// P(A), P(B)는 사전확률
// P(X|A), P(X,B)를 우도(데이터를 얼마나 잘 설명하는지의 척도)
```

## Bag of Words
- 어떤 문장이 있다고 할 때 이 문장의 종류가 A인지 B인지 판단
- 단어(형태소)를 분리해서 A 종류에서의 각 단어의 발생확률의 곱과 B 종류에서의 각 단어의 발생확률 곱을 비교
- 이때 학습 데이터에 존재하지 않아 발생확률이 0이 될 수 있는 데이터에 대해서는 여러가지 전처리 방법이 존재
	- 아주 작은 확률을 부여하는 방법이 가능

# 비지도학습
label이 지정되지 않은 데이터를 통해서 자동으로 패턴을 파악

## Hard or Soft Clustering
- Hard: 데이터가 명확히 분류될 때(ex. 개, 고양이) 
- Soft: 데이터가 여러 클러스터의 확률 집합일 때(ex. 도서 장르)

## PCA(주성분 분석 / 차원 축소)
- 데이터를 구성하는 요소의 차원을 클러스터링 및 시각화에 용이하도록 저차원으로 줄이는 것

## K-means
- K개 Centroid(중심)를 데이터 중 임의로 선정
- 각각의 데이터에 대해 거리가 가까운 centroid가 동일한 것끼리 클러스터를 설정
- 설정된 클러스터의 데이터 중심점을 새로운 Centroid로 설정
- 클러스터의 변화가 없을때까지 위의 과정을 반복
